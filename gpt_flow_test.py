from openai import OpenAI
import base64
import json
import os
from datetime import datetime

"""
ìµœì¢…ì ìœ¼ë¡œ  gpt apië¥¼ ì´ìš©í•˜ì—¬ ì¼ê¸°ë¥¼ ìƒì„±í•˜ê³ , data ì •ë³´ë¥¼ backendì— ë³´ë‚´ê¸° ìœ„í•´ json íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í…ŒìŠ¤íŒ…ì½”ë“œ
gpt apiì™€ ëŒ€í™”ë¥¼ í•˜ë©° gptëŠ” ì‚¬ì§„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì‚¬ìš©ìë¡œë¶€í„° ì–»ê³ 
ê·¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¼ê¸°ë¥¼ ìƒì„±í•œë‹¤

<logic>
1. gpt apië¥¼ 2ê°œë¥¼ ë‹¤ë¥¸ í•¨ìˆ˜ë¡œ ì´ìš©í•˜ì—¬ ë¶ˆëŸ¬ì˜¨ë‹¤.(ëŒ€í™”ìš©, ì´ë¯¸ì§€ ìº¡ì…˜ìš©) ê°ê° ë‹¤ë¥¸ í”„ë¡¬í¬íŠ¸ë¥¼ ê°–ëŠ”ë‹¤.
2. ë‹¨ìˆœ textë¥¼ ì´ìš©í•œ ëŒ€í™”ìš© api í˜¸ì¶œ í•¨ìˆ˜ì—ì„œëŠ” ì‚¬ìš©ìì™€ ëŒ€í™”í•˜ë©° ì‚¬ì§„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì–»ëŠ”ë‹¤
3. ì´ë•Œ ëŒ€í™”ìš© api(ì²«ë²ˆì§¸)ì—ì„œëŠ” ëŒ€í™” ë‚´ì—­ì„ ë”•ì…”ë„ˆë¦¬ì— ì €ì¥í•´ë†“ìŒìœ¼ë¡œì¨ ì¶”í›„ ì¼ê¸°ë¥¼ ìƒì„±í•  ë•Œ ì°¸ê³ í•œë‹¤
4. ëŒ€í™”ê°€ ëë‚˜ê³  ì¼ê¸°ë¥¼ ìƒì„±í•  ë•ŒëŠ” ë‘ë²ˆì§¸ ì´ë¯¸ì§€ ìº¡ì…˜ gpt apiì—ì„œëŠ” ë”•ì…”ë„ˆë¦¬ì— ì €ì¥ëœ ëŒ€í™” ë‚´ì—­ì„ ì „ë¶€ ê°–ê³ ì˜¨ë‹¤
5. ê·¸ë¦¬í•˜ì—¬ ëŒ€í™” ë‚´ì—­ì„ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì´ë¯¸ì§€ë¡œë¶€í„° ì¼ê¸°ë¥¼ ìƒì„±í•œë‹¤
6. ì‚¬ìš©ìì˜ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©í•œ ì´ë¯¸ì§€ ì •ë³´ì™€, ì¼ê¸° ë‚´ìš©ì„ json íŒŒì¼ë¡œ ì €ì¥í•œë‹¤
"""

client = OpenAI(
    api_key="OPENAI_API_KEY",  
)




# ëŒ€í™” ë©”ì‹œì§€ ì¶”ê°€ í•¨ìˆ˜
def add_message(conversation_history, gpt_content, user_content):
    if user_content:
        conversation_history["user"].append(user_content)
    if gpt_content:
        conversation_history["assistant"].append(gpt_content)

# ëŒ€í™”ìš© GPT API í˜¸ì¶œ í•¨ìˆ˜
def chat_with_gpt(conversation_history):
    messages = [{"role": "user", "content": conversation_history["text_prompt"]}]
    for user_msg, gpt_msg in zip(conversation_history["user"], conversation_history["assistant"]):
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": gpt_msg})

    user_input = input("You: ")
    if user_input.strip().lower() == "end":
        return None, False

    messages.append({"role": "user", "content": user_input})

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
    )

    gpt_response = response.choices[0].message.content.strip()
    add_message(conversation_history, gpt_response, user_input)

    return gpt_response, True

# ì´ë¯¸ì§€ + ëŒ€í™” ê¸°ë°˜ GPT ì¼ê¸° ìƒì„± í•¨ìˆ˜
def generate_diary_with_image(conversation_history, encoded_image):
    messages = [{"role": "user", "content": conversation_history["img_prompt"]}]
    for user_msg, assistant_msg in zip(conversation_history["user"], conversation_history["assistant"]):
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": assistant_msg})

    messages.append({
        "role": "user",
        "content": [
            {"type": "text", "text": "ìœ„ì˜ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì´ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¼ê¸°ë¥¼ ì‘ì„±í•´ì¤˜."},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{encoded_image}",
                    "detail": "high"
                }
            }
        ]
    })

    response = client.chat.completions.create(
        model="ft:gpt-4o-2024-08-06:personal:capstone150img:BMxNfNjK",
        messages=messages,
        temperature=0.7
    )

    return response.choices[0].message.content.strip()

# ì´ˆê¸° í”„ë¡¬í”„íŠ¸
text_prompt = "ë‚´ê°€ ë„ˆì—ê²Œ ì‚¬ì§„ì„ ì£¼ê¸° ì „ ì‚¬ì§„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì¤„ê±°ì•¼. ë‚´ê°€ ë„ˆì—ê²Œ ì£¼ëŠ” ì •ë³´ë¥¼ ë„ˆëŠ” ì˜ ë“£ê³  ë‚˜ì¤‘ì— ì¼ê¸°ë¥¼ ì‘ì„±í•  ë•Œ ì‚¬ìš©í•´ì¤˜. ì¶”ê°€ë¡œ ê¶ê¸ˆí•œê²Œ ì¤‘ê°„ì— ìƒê¸°ë©´ ì–¸ì œë“  ë¬¼ì–´ë´. ì´ì „ ëŒ€í™”ë‚´ì—¬ì„ ì°¸ê³ í•´ì„œ ëŒ€í™”í•´ì¤˜. "
img_prompt = "ë„ˆëŠ” ë‚˜ì˜ ê·¸ë¦¼ì¼ê¸°ë¥¼ ëŒ€ì‹  ì‘ì„±í•´ì£¼ëŠ” ì—­í• ì´ì•¼. ë‚´ê°€ ë„ˆì—ê²Œ ì‚¬ì§„ì„ ë³´ì—¬ì£¼ë©´ ë„ˆëŠ” ì‚¬ì§„ì„ ë³´ê³  ê·¸ ë‚  ìˆì—ˆë˜ ì¼ê¸°ë¥¼ ê°„ë‹¨í•˜ê²Œ ì‘ì„±í•´ì¤˜. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì´ì „ ë‚´ìš©ë“¤ì„ ì—°ê²°í•´ì„œ ì‘ì„±í•´ì¤˜. ì¼ê¸°ë¥¼ í’ë¶€í•˜ê²Œ ì‘ì„±í•´ì¤˜. ì¼ê¸°ì˜ ë‚´ìš© ì™¸ì—ëŠ” ì‘ì„±í•˜ì§€ë§ˆ."

conversation_history = {
    "text_prompt": text_prompt,
    "img_prompt": img_prompt,
    "user": [],
    "assistant": []
}

# ì§ì ‘ ì§€ì •í•œ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
image_paths = [
    "./data/fine_tuning_img/003.jpg",
    "./data/fine_tuning_img/004.jpg",
    "./data/fine_tuning_img/005.jpg"
]

# ìµœì¢… ê²°ê³¼ ì €ì¥ ë”•ì…”ë„ˆë¦¬
final_output = {}
current_date = datetime.now().strftime("%Y-%m-%d")
final_output[current_date] = []

for idx, image_path in enumerate(image_paths):
    print(f"\nğŸ–¼ï¸ í˜„ì¬ ì´ë¯¸ì§€: {image_path}")

    # ì‚¬ìš©ìì™€ ëŒ€í™” ì‹œì‘
    keep_going = True
    print("GPT: ì´ ì‚¬ì§„ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”! ì–´ë–¤ í•˜ë£¨ë¥¼ ë³´ëƒˆë‚˜ìš”?")
    while keep_going:
        gpt_response, keep_going = chat_with_gpt(conversation_history)
        if gpt_response:
            print(f"GPT: {gpt_response}")

    # ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(image_path, "rb") as img_file:
        encoded_image = base64.b64encode(img_file.read()).decode("utf-8")

    print("\nğŸ“ GPTê°€ ì¼ê¸°ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
    diary_text = generate_diary_with_image(conversation_history, encoded_image)
    print(f"GPT: {diary_text}")

    final_output[current_date].append({
        "image_index": image_path.split("/")[-1].split(".")[0],
        "image_base64": encoded_image,
        "diary": diary_text
    })

# JSON íŒŒì¼ ì €ì¥
output_json_path = "./data/diary_output_all.json"
with open(output_json_path, "w", encoding="utf-8") as f:
    json.dump(final_output, f, ensure_ascii=False, indent=2)

print(f"\nâœ… ì „ì²´ ì¼ê¸°ê°€ {output_json_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
# ì „ì²´ ëŒ€í™” ë‚´ì—­ ì¶œë ¥ í•¨ìˆ˜
def print_conversation_history(conversation_history):
    print("\nğŸ—£ï¸ ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ì—­:\n")
    for i in range(len(conversation_history["user"])):
        print(f"User: {conversation_history['user'][i]}")
        if i < len(conversation_history["assistant"]):
            print(f"GPT: {conversation_history['assistant'][i]}")
        print("-")

# ëŒ€í™” ë‚´ì—­ ì¶œë ¥
print_conversation_history(conversation_history)