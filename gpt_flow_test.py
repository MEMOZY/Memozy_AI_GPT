from openai import OpenAI
import base64
import json
import os
from datetime import datetime
from io import BytesIO
from PIL import Image

client = OpenAI(
    api_key="openai_api_key",  
)

# ëŒ€í™” ë©”ì‹œì§€ ì¶”ê°€ í•¨ìˆ˜
def add_message(conversation_history, gpt_content, user_content):
    if user_content:
        conversation_history["user"].append(user_content)
    if gpt_content:
        conversation_history["assistant"].append(gpt_content)

# ì´ë¯¸ì§€ ê¸°ë°˜ ì²« ì½”ë©˜íŠ¸ ìƒì„± í•¨ìˆ˜
def generate_first_comment(encoded_image,prompt):
    messages = [
        {
            "role": "system",
            "content": f"{prompt}"
        },
        {
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{encoded_image}",
                        "detail": "low"
                    }
                }
            ]
        }
    ]

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages
        # temperature=0.5
    )
    # ì²« ì½”ë©˜íŠ¸ ë‚´ìš© ëŒ€í™”ë‚´ì—­ ì¶”ê°€
    add_message(conversation_history, response.choices[0].message.content.strip(), prompt)

    return response.choices[0].message.content.strip()

# ëŒ€í™”ìš© GPT API í˜¸ì¶œ í•¨ìˆ˜ (ìµœëŒ€ 3íšŒ ëŒ€í™”)
def chat_with_gpt(conversation_history, iter_num=3):
    messages = [{"role": "user", "content": conversation_history["text_prompt"]}]
    for user_msg, gpt_msg in zip(conversation_history["user"], conversation_history["assistant"]):
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": gpt_msg})

    for turn in range(iter_num):
        user_input = input("You: ")
        if user_input.strip().lower() == "end" or turn == iter_num - 1: # ì‚¬ìš©ìê°€ endë¥¼ ì…ë ¥í•˜ê±°ë‚˜ ì§€ì • ë°˜ë³µ ìˆ˜ì— ë„ë‹¬í•˜ë©´ ëŒ€í™” ì¢…ë£Œ
            break

        messages.append({"role": "user", "content": user_input})

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=messages
        )

        gpt_response = response.choices[0].message.content.strip()
        add_message(conversation_history, gpt_response, user_input)

        print(f"GPT: {gpt_response}")

        # ëŒ€í™” ì—…ë°ì´íŠ¸
        messages.append({"role": "assistant", "content": gpt_response})

    print("\nğŸ’¬ ëŒ€í™”ê°€ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì´ì œ ì¼ê¸°ë¥¼ ìƒì„±í• ê²Œìš”!\n")

# ì´ë¯¸ì§€ + ëŒ€í™” ê¸°ë°˜ GPT ì¼ê¸° ìƒì„± í•¨ìˆ˜
def generate_diary_with_image(conversation_history, encoded_image):
    messages = [{"role": "user", "content": conversation_history["img_prompt"]}]
    for user_msg, assistant_msg in zip(conversation_history["user"], conversation_history["assistant"]):
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": assistant_msg})

    messages.append({
        "role": "user",
        "content": [
            {"type": "text", "text": "ìœ„ì˜ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ì´ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¼ê¸°ë¥¼ ì‘ì„±í•´ì¤˜."},
            {
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{encoded_image}",
                    "detail": "high"
                }
            }
        ]
    })

    response = client.chat.completions.create(
        model="ft:gpt-4o-2024-08-06:personal:capstone150img:BMxNfNjK",
        messages=messages
        # temperature=0.7
    )

    return response.choices[0].message.content.strip()

# ì´ˆê¸° í”„ë¡¬í”„íŠ¸
first_comment_prompt="ë„ˆëŠ” ì‚¬ìš©ìì˜ ì‚¬ì§„ì¼ê¸°ì— ëŒ€í•´ ë¨¼ì € ì‚¬ì§„ì„ ë³´ê³  ì¶”ì¸¡í•˜ì—¬ ì‚¬ìš©ìë¡œë¶€í„° ëŒ€í™”ë¥¼ ìœ ë„í•˜ëŠ” ì—­í• ì´ì•¼. ì´ë¯¸ì§€ë¥¼ ë³´ê³  '~~í•œ ê²ƒê°™ì€ ì‚¬ì§„ì´ë„¤ìš”. ì´ ì‚¬ì§„ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”!' ë¼ëŠ” ì‹ìœ¼ë¡œ ë§í•´."
text_prompt = "ë‚´ê°€ ë„ˆì—ê²Œ ì‚¬ì§„ì— ëŒ€í•œ ì •ë³´ë¥¼ ì•Œë ¤ì¤„ê±°ì•¼. ë„ˆëŠ” ì˜ ë“£ê³  ì´í›„ ì¼ê¸° ì‘ì„±í•  ë•Œ í™œìš©í•´ì¤˜. ì¶”ê°€ ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ë©´ ì§ˆë¬¸í•´ë„ ì¢‹ì•„. ëŒ€í™”ëŠ” ì´ì „ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€."
img_prompt = "ë„ˆëŠ” ë‚˜ì˜ ê·¸ë¦¼ì¼ê¸°ë¥¼ ëŒ€ì‹  ì‘ì„±í•´ì£¼ëŠ” ì—­í• ì´ì•¼. ë‚´ê°€ ë„ˆì—ê²Œ ì‚¬ì§„ì„ ë³´ì—¬ì£¼ë©´ ì‚¬ì§„ì„ ë³´ê³ , ê·¸ë¦¬ê³  ëŒ€í™”í–ˆë˜ ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ í’ë¶€í•œ ì¼ê¸°ë¥¼ ì‘ì„±í•´ì¤˜. ì¼ê¸°ì˜ ë‚´ìš© ì™¸ì—ëŠ” ì“°ì§€ë§ˆ."

conversation_history = {
    "text_prompt": text_prompt,
    "img_prompt": img_prompt,
    "user": [],
    "assistant": []
}

# ì§ì ‘ ì§€ì •í•œ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
image_paths = [
    "./data/fine_tuning_img/003.jpg",
    "./data/fine_tuning_img/004.jpg",
    "./data/fine_tuning_img/005.jpg"
]

# ìµœì¢… ê²°ê³¼ ì €ì¥ ë”•ì…”ë„ˆë¦¬
final_output = {}
current_date = datetime.now().strftime("%Y-%m-%d")
final_output[current_date] = []

for idx, image_path in enumerate(image_paths):
    print(f"\nğŸ–¼ï¸ í˜„ì¬ ì´ë¯¸ì§€: {image_path}")

    # ì´ë¯¸ì§€ ì¸ì½”ë”©
    with open(image_path, "rb") as img_file:
        encoded_image = base64.b64encode(img_file.read()).decode("utf-8")

    # ì´ë¯¸ì§€ ê¸°ë°˜ ì²« ì½”ë©˜íŠ¸ ë°›ê¸°
    first_comment = generate_first_comment(encoded_image, first_comment_prompt)
    print(f"GPT (ì²« ì¸ì‚¬): {first_comment}")

    # ì‚¬ìš©ìì™€ ëŒ€í™” ì‹œì‘ (ìµœëŒ€ 3íšŒ)
    chat_with_gpt(conversation_history,3) # 3=ëª‡ë²ˆ ëŒ€í™”í• ê±´ì§€

    # ì¼ê¸° ìƒì„±
    print("ğŸ“ GPTê°€ ì¼ê¸°ë¥¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...")
    diary_text = generate_diary_with_image(conversation_history, encoded_image)
    print(f"GPT (ì¼ê¸°): {diary_text}")

    final_output[current_date].append({
        "image_index": image_path.split("/")[-1].split(".")[0],
        "image_base64": encoded_image,
        "diary": diary_text
    })

# JSON íŒŒì¼ ì €ì¥
output_json_path = "./data/diary_output_all.json"
with open(output_json_path, "w", encoding="utf-8") as f:
    json.dump(final_output, f, ensure_ascii=False, indent=2)

print(f"\nâœ… ì „ì²´ ì¼ê¸°ê°€ {output_json_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ì „ì²´ ëŒ€í™” ë‚´ì—­ ì¶œë ¥ í•¨ìˆ˜
def print_conversation_history(conversation_history):
    print("\nğŸ—£ï¸ ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™” ë‚´ì—­:\n")
    for i in range(len(conversation_history["user"])):
        print(f"User: {conversation_history['user'][i]}")
        if i < len(conversation_history["assistant"]):
            print(f"GPT: {conversation_history['assistant'][i]}")
        print("-")

# ëŒ€í™” ë‚´ì—­ ì¶œë ¥
print_conversation_history(conversation_history)
